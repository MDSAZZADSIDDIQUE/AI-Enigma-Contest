{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import KalmanFilter\n",
    "from sort import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.190  Python-3.8.18 torch-2.0.1+cpu CPU (AMD Ryzen 5 3550H with Radeon Vega Mobile Gfx)\n",
      "Model summary (fused): 268 layers, 43607379 parameters, 0 gradients, 164.8 GFLOPs\n",
      "\n",
      "image 1/1 d:\\AI Enigma Contest\\Light Detection\\Field Dataset\\train\\images\\960x0 (10).jpg: 256x480 1 light, 749.4ms\n",
      "Speed: 0.0ms preprocess, 749.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n",
      " Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=predict model=\"best (3).pt\" conf=0.75 source=\"Field Dataset/train/images/960x0 (10).jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x480 2 lights, 744.9ms\n",
      "Speed: 0.0ms preprocess, 744.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 715.3ms\n",
      "Speed: 0.0ms preprocess, 715.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 719.6ms\n",
      "Speed: 1.0ms preprocess, 719.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 717.6ms\n",
      "Speed: 0.9ms preprocess, 717.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 696.0ms\n",
      "Speed: 1.0ms preprocess, 696.0ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 749.8ms\n",
      "Speed: 0.9ms preprocess, 749.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 723.6ms\n",
      "Speed: 2.0ms preprocess, 723.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 711.5ms\n",
      "Speed: 1.1ms preprocess, 711.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 751.8ms\n",
      "Speed: 2.0ms preprocess, 751.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 730.7ms\n",
      "Speed: 2.0ms preprocess, 730.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 754.2ms\n",
      "Speed: 2.0ms preprocess, 754.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 716.2ms\n",
      "Speed: 2.0ms preprocess, 716.2ms inference, 13.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 781.3ms\n",
      "Speed: 0.0ms preprocess, 781.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 697.0ms\n",
      "Speed: 2.0ms preprocess, 697.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 768.2ms\n",
      "Speed: 0.0ms preprocess, 768.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 727.9ms\n",
      "Speed: 1.3ms preprocess, 727.9ms inference, 7.5ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 718.5ms\n",
      "Speed: 0.0ms preprocess, 718.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 746.3ms\n",
      "Speed: 2.3ms preprocess, 746.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 790.7ms\n",
      "Speed: 0.0ms preprocess, 790.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 731.9ms\n",
      "Speed: 1.0ms preprocess, 731.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 731.0ms\n",
      "Speed: 1.0ms preprocess, 731.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 800.4ms\n",
      "Speed: 1.4ms preprocess, 800.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 746.5ms\n",
      "Speed: 1.8ms preprocess, 746.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 746.9ms\n",
      "Speed: 1.0ms preprocess, 746.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 4 lights, 748.7ms\n",
      "Speed: 2.0ms preprocess, 748.7ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 746.4ms\n",
      "Speed: 2.0ms preprocess, 746.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 736.0ms\n",
      "Speed: 1.0ms preprocess, 736.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 782.2ms\n",
      "Speed: 0.0ms preprocess, 782.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 730.5ms\n",
      "Speed: 2.0ms preprocess, 730.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 728.9ms\n",
      "Speed: 1.0ms preprocess, 728.9ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 730.1ms\n",
      "Speed: 0.0ms preprocess, 730.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 746.0ms\n",
      "Speed: 2.0ms preprocess, 746.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 812.6ms\n",
      "Speed: 2.0ms preprocess, 812.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 780.2ms\n",
      "Speed: 1.0ms preprocess, 780.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 796.9ms\n",
      "Speed: 2.0ms preprocess, 796.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 805.5ms\n",
      "Speed: 0.0ms preprocess, 805.5ms inference, 9.7ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 713.0ms\n",
      "Speed: 1.5ms preprocess, 713.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 780.4ms\n",
      "Speed: 1.0ms preprocess, 780.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 747.1ms\n",
      "Speed: 2.0ms preprocess, 747.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 747.6ms\n",
      "Speed: 0.0ms preprocess, 747.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 753.9ms\n",
      "Speed: 2.0ms preprocess, 753.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 730.1ms\n",
      "Speed: 2.0ms preprocess, 730.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 730.0ms\n",
      "Speed: 2.0ms preprocess, 730.0ms inference, 16.7ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 746.5ms\n",
      "Speed: 0.0ms preprocess, 746.5ms inference, 15.1ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 781.4ms\n",
      "Speed: 2.0ms preprocess, 781.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 752.6ms\n",
      "Speed: 2.0ms preprocess, 752.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 746.9ms\n",
      "Speed: 1.0ms preprocess, 746.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 763.3ms\n",
      "Speed: 2.0ms preprocess, 763.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 747.6ms\n",
      "Speed: 2.0ms preprocess, 747.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 779.2ms\n",
      "Speed: 2.0ms preprocess, 779.2ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 776.3ms\n",
      "Speed: 0.0ms preprocess, 776.3ms inference, 2.5ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 744.6ms\n",
      "Speed: 0.0ms preprocess, 744.6ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 784.9ms\n",
      "Speed: 0.0ms preprocess, 784.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 714.8ms\n",
      "Speed: 0.0ms preprocess, 714.8ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 752.1ms\n",
      "Speed: 1.0ms preprocess, 752.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 754.5ms\n",
      "Speed: 0.0ms preprocess, 754.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 746.5ms\n",
      "Speed: 0.0ms preprocess, 746.5ms inference, 16.1ms postprocess per image at shape (1, 3, 256, 480)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "\n",
    "# cap = cv2.VideoCapture(1)  # For Webcam\n",
    "# cap.set(3, 1280)\n",
    "# cap.set(4, 720)\n",
    "cap = cv2.VideoCapture(\"960x0_(5)_V1.mp4\")  # For Video\n",
    "\n",
    "\n",
    "model = YOLO(\"best (3).pt\")\n",
    "\n",
    "classNames = [\"light\"]\n",
    "\n",
    "\n",
    "while True:\n",
    "    new_frame_time = time.time()\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            cvzone.cornerRect(img, (x1, y1, w, h))\n",
    "            # Confidence\n",
    "            conf = math.ceil((box.conf[0] * 100)) / 100\n",
    "            # Class Name\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0, x1), max(35, y1)), scale=1, thickness=1)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "  \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x480 2 lights, 760.0ms\n",
      "Speed: 15.4ms preprocess, 760.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          0           2         503         195           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 729.4ms\n",
      "Speed: 4.0ms preprocess, 729.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          0           2         503         195           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 715.6ms\n",
      "Speed: 2.0ms preprocess, 715.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          0           2         503         195           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 743.9ms\n",
      "Speed: 2.0ms preprocess, 743.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          0           2         503         195           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 820.5ms\n",
      "Speed: 2.0ms preprocess, 820.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.16014       1.969      503.62      195.03           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 715.4ms\n",
      "Speed: 1.0ms preprocess, 715.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.15293      1.9594      503.86      195.04           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 730.8ms\n",
      "Speed: 1.0ms preprocess, 730.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.11277      1.9583      503.97      195.04           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 748.6ms\n",
      "Speed: 1.0ms preprocess, 748.6ms inference, 15.6ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.073979      1.9604      504.02      195.04           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 768.1ms\n",
      "Speed: 2.0ms preprocess, 768.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   -0.12148      1.9795      503.52      195.02           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 780.5ms\n",
      "Speed: 2.0ms preprocess, 780.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   -0.14975      1.9903      503.29      195.01           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 764.7ms\n",
      "Speed: 2.0ms preprocess, 764.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   -0.12898      1.9965      503.17         195           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 777.8ms\n",
      "Speed: 2.0ms preprocess, 777.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.071981      1.9893      503.61      195.01           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 749.1ms\n",
      "Speed: 1.0ms preprocess, 749.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0.10994      1.9857       503.8      195.01           2]\n",
      "[        477           4         958         208           1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 752.2ms\n",
      "Speed: 2.0ms preprocess, 752.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -48.356       20.78      378.11      218.62           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 721.7ms\n",
      "Speed: 1.0ms preprocess, 721.7ms inference, 15.6ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -53.363      25.898      317.88      229.39           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 743.8ms\n",
      "Speed: 2.0ms preprocess, 743.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -45.537        25.6      286.24      235.48           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 733.5ms\n",
      "Speed: 1.0ms preprocess, 733.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     -35.37      23.434      267.95      239.62           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 779.5ms\n",
      "Speed: 2.0ms preprocess, 779.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -26.184      20.545      256.52       242.4           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 763.9ms\n",
      "Speed: 2.0ms preprocess, 763.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -18.834      18.103      249.07      245.28           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 765.9ms\n",
      "Speed: 1.0ms preprocess, 765.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -13.159       15.61      244.03      247.11           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 760.7ms\n",
      "Speed: 2.0ms preprocess, 760.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -8.8997      13.587      240.62      248.74           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 808.1ms\n",
      "Speed: 2.0ms preprocess, 808.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     -5.736      11.939      238.32      250.11           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 730.6ms\n",
      "Speed: 1.0ms preprocess, 730.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     -3.398      10.596      236.79      251.23           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 750.8ms\n",
      "Speed: 2.0ms preprocess, 750.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -1.6741      9.5018       235.8      252.14           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 4 lights, 720.7ms\n",
      "Speed: 1.5ms preprocess, 720.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   -0.40435      8.6095       235.2      252.87           2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 1 light, 746.6ms\n",
      "Speed: 2.0ms preprocess, 746.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 752.5ms\n",
      "Speed: 1.0ms preprocess, 752.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 726.9ms\n",
      "Speed: 2.0ms preprocess, 726.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 724.5ms\n",
      "Speed: 1.0ms preprocess, 724.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 771.2ms\n",
      "Speed: 1.0ms preprocess, 771.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 735.2ms\n",
      "Speed: 2.0ms preprocess, 735.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 720.1ms\n",
      "Speed: 2.0ms preprocess, 720.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 724.6ms\n",
      "Speed: 2.0ms preprocess, 724.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 711.8ms\n",
      "Speed: 1.0ms preprocess, 711.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 751.0ms\n",
      "Speed: 2.0ms preprocess, 751.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 755.8ms\n",
      "Speed: 0.0ms preprocess, 755.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 723.9ms\n",
      "Speed: 2.0ms preprocess, 723.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 1 light, 769.1ms\n",
      "Speed: 2.0ms preprocess, 769.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 722.4ms\n",
      "Speed: 2.0ms preprocess, 722.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 719.6ms\n",
      "Speed: 2.0ms preprocess, 719.6ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 738.9ms\n",
      "Speed: 1.0ms preprocess, 738.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n",
      "0: 256x480 2 lights, 764.4ms\n",
      "Speed: 2.0ms preprocess, 764.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          5           2         960         221           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 688.1ms\n",
      "Speed: 2.0ms preprocess, 688.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          5           2         960         221           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 746.2ms\n",
      "Speed: 1.0ms preprocess, 746.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          5           2         960         221           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 779.5ms\n",
      "Speed: 2.0ms preprocess, 779.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          5           2         960         221           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 744.4ms\n",
      "Speed: 1.0ms preprocess, 744.4ms inference, 15.6ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          5           2         960         221           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 718.3ms\n",
      "Speed: 2.0ms preprocess, 718.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          7         190         960         480           4]\n",
      "[          5           2         960         221           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 736.5ms\n",
      "Speed: 1.0ms preprocess, 736.5ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          7         190         960         480           4]\n",
      "[          5           2         960         221           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 749.3ms\n",
      "Speed: 2.0ms preprocess, 749.3ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          7         190         960         480           4]\n",
      "[          5           2         960         221           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 735.4ms\n",
      "Speed: 0.0ms preprocess, 735.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[          7         190         960         480           4]\n",
      "[          5           2         960         221           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 779.7ms\n",
      "Speed: 1.0ms preprocess, 779.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      6.206     0.80836      959.46      217.54           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 798.2ms\n",
      "Speed: 2.0ms preprocess, 798.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     6.8516     0.72937      959.06      215.88           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 719.9ms\n",
      "Speed: 2.0ms preprocess, 719.9ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     7.1953     0.96544      958.81      215.01           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 745.8ms\n",
      "Speed: 1.0ms preprocess, 745.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     7.3684      1.2448      958.67      214.52           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 713.7ms\n",
      "Speed: 2.0ms preprocess, 713.7ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     7.4421      1.4862       958.6      214.22           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 752.1ms\n",
      "Speed: 1.0ms preprocess, 752.1ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     7.4573      1.6742      958.59      214.03           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 797.0ms\n",
      "Speed: 0.0ms preprocess, 797.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     6.1303       2.106      957.94      213.62           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 768.2ms\n",
      "Speed: 2.0ms preprocess, 768.2ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     5.4777       2.417      957.85      213.33           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 745.9ms\n",
      "Speed: 2.0ms preprocess, 745.9ms inference, 1.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     6.4199      2.3528      958.59      213.42           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 725.8ms\n",
      "Speed: 2.0ms preprocess, 725.8ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     5.4818      2.5915      958.21       213.2           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 716.0ms\n",
      "Speed: 2.0ms preprocess, 716.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     5.0096      2.7625      958.18      213.05           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 750.4ms\n",
      "Speed: 1.0ms preprocess, 750.4ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     6.0563       2.601      958.92      213.23           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 256x480 2 lights, 938.0ms\n",
      "Speed: 2.0ms preprocess, 938.0ms inference, 0.0ms postprocess per image at shape (1, 3, 256, 480)\n",
      "WARNING  'source' is missing. Using 'source=C:\\Users\\mdsaz\\.conda\\envs\\likhon\\Lib\\site-packages\\ultralytics\\assets'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     5.1762      2.7656      958.51      213.08           3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/2 C:\\Users\\mdsaz\\.conda\\envs\\likhon\\Lib\\site-packages\\ultralytics\\assets\\bus.jpg: 480x384 8 lights, 1343.8ms\n",
      "image 2/2 C:\\Users\\mdsaz\\.conda\\envs\\likhon\\Lib\\site-packages\\ultralytics\\assets\\zidane.jpg: 288x480 3 lights, 926.6ms\n",
      "Speed: 0.6ms preprocess, 1135.2ms inference, 0.0ms postprocess per image at shape (1, 3, 288, 480)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     27.948      25.265      903.87      236.36           3]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 96\u001b[0m\n\u001b[0;32m     93\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(img,\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZone 3: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzone2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m),(\u001b[38;5;241m155\u001b[39m,\u001b[38;5;241m400\u001b[39m),cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_PLAIN,\u001b[38;5;241m3\u001b[39m,(\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m255\u001b[39m),\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     94\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(img,\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZone 4: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzone1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m),(\u001b[38;5;241m555\u001b[39m,\u001b[38;5;241m400\u001b[39m),cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_PLAIN,\u001b[38;5;241m3\u001b[39m,(\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m255\u001b[39m),\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSunlight amount detector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m25\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\likhon\\lib\\site-packages\\ultralytics\\utils\\patches.py:54\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(winname, mat)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(winname: \u001b[38;5;28mstr\u001b[39m, mat: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Displays an image in the specified window.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m        winname (str): Name of the window.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m        mat (np.ndarray): Image to be shown.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[43m_imshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwinname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43municode_escape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "from filterpy.kalman import KalmanFilter\n",
    "import argparse\n",
    "import time\n",
    "import glob\n",
    "from skimage import io\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sort import *\n",
    "\n",
    "# cap = cv2.VideoCapture(1)  # For Webcam\n",
    "# cap.set(3, 1280)\n",
    "# cap.set(4, 720)\n",
    "cap = cv2.VideoCapture(\"960x0_(5)_V1.mp4\")  # For Video\n",
    "\n",
    "\n",
    "model = YOLO(\"best (3).pt\")\n",
    "\n",
    "classNames = ['light']\n",
    "tracker = Sort(max_age=20, min_hits=3, iou_threshold=0.3)\n",
    "zone1 = 0\n",
    "zone2 = 0\n",
    "zone3 = 0\n",
    "zone4 = 0\n",
    "\n",
    "limits = [500, 300, 1000, 300]\n",
    "limits2 = [0, 300, 500, 300]\n",
    "limits3 = [500, 150, 1000, 150]\n",
    "limits4 = [0, 150, 500, 150]\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "    detections = np.empty((0, 5))\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            # Bounding Box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            # cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,255),3)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            cvzone.cornerRect(img, (x1, y1, w, h))\n",
    "            # Confidence\n",
    "            conf = math.ceil((box.conf[0] * 100)) / 100\n",
    "            # Class Name\n",
    "            cls = int(box.cls[0])\n",
    "            if conf > 0.5:\n",
    "                currentArray = np.array([x1, y1, x2, y2, conf])\n",
    "                detections = np.vstack((detections, currentArray))\n",
    "    resultsTracker = tracker.update(detections)\n",
    "\n",
    "#     cv2.line(img, (limits[0], limits[1]), (limits[2], limits[3]), (0, 0, 255), 5)\n",
    "#     cv2.line(img, (limits2[0], limits2[1]), (limits2[2], limits2[3]), (255, 0, 0), 5)\n",
    "#     cv2.line(img, (limits3[0], limits3[1]), (limits3[2], limits3[3]), (0, 255, 0), 5)\n",
    "#     cv2.line(img, (limits4[0], limits4[1]), (limits4[2], limits4[3]), (255, 0, 255), 5)\n",
    "\n",
    "    \n",
    "    for result in resultsTracker:\n",
    "        x1, y1, x2, y2, id = result\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        print(result)\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        cvzone.cornerRect(img, (x1, y1, w, h), l=9, rt=2, colorR=(255, 0, 255))\n",
    "        cvzone.putTextRect(img, f' {int(id)}', (max(0, x1), max(35, y1)),\n",
    "                           scale=2, thickness=3, offset=10)\n",
    "\n",
    "        cx, cy = x1 + w // 2, y1 + h // 2\n",
    "        cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
    "        if limits[0] < cx < limits[2] and limits[1] - 150 < cy < limits[1] + 150:\n",
    "            zone1 = zone1 + 1\n",
    "#             cv2.line(img, (limits[0], limits[1]), (limits[2], limits[3]), (0, 255, 0), 5)\n",
    "        if limits2[0] < cx < limits2[2] and limits2[1] - 150 < cy < limits2[1] + 150:\n",
    "            zone2 = zone2 + 1\n",
    "#             cv2.line(img, (limits2[0], limits2[1]), (limits2[2], limits2[3]), (0, 255, 0), 5)\n",
    "        if limits3[0] < cx < limits3[2] and limits3[1] - 150 < cy < limits3[1] + 150:\n",
    "            zone3 = zone3 + 1\n",
    "#             cv2.line(img, (limits3[0], limits3[1]), (limits3[2], limits3[3]), (0, 255, 0), 5)\n",
    "        if limits4[0] < cx < limits4[2] and limits4[1] - 150 < cy < limits4[1] + 150:\n",
    "            zone4 = zone4 + 1\n",
    "            continue\n",
    "#             cv2.line(img, (limits4[0], limits4[1]), (limits4[2], limits4[3]), (0, 255, 0), 5)\n",
    "    \n",
    "    cv2.putText(img,str(f\"Zone 1: {zone4}s\"),(155,100),cv2.FONT_HERSHEY_PLAIN,3,(50,50,255),3)\n",
    "    cv2.putText(img,str(f\"Zone 2: {zone3}s\"),(555,100),cv2.FONT_HERSHEY_PLAIN,3,(50,50,255),3)\n",
    "    cv2.putText(img,str(f\"Zone 3: {zone2}s\"),(155,400),cv2.FONT_HERSHEY_PLAIN,3,(50,50,255),3)\n",
    "    cv2.putText(img,str(f\"Zone 4: {zone1}s\"),(555,400),cv2.FONT_HERSHEY_PLAIN,3,(50,50,255),3)\n",
    "\n",
    "    cv2.imshow(\"Sunlight amount detector\", img)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "  \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
